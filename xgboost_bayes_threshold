import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from skopt import BayesSearchCV
from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix

# 1. Generate an extremely imbalanced dataset (ratio â‰ˆ 1:50000)
# Here we use make_classification with weights set so that the positive class is very rare [1]
n_samples = 500001  # total samples
# Calculate weights: ~500000 negatives for every 1 positive sample
weights = [500000 / 500001, 1 / 500001]
X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=10,
                           n_redundant=5, n_clusters_per_class=1, weights=weights,
                           flip_y=0, random_state=42)

# 2. Split the dataset into training and validation sets with stratification to maintain imbalance [1]
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 3. Compute scale_pos_weight based on the training set counts
# This ratio helps the model weigh the minority class higher, which is critical for imbalanced data [1]
neg, pos = np.bincount(y_train)
scale_pos_weight = neg / pos
print("Calculated scale_pos_weight:", scale_pos_weight)

# 4. Create an XGBClassifier for hyperparameter tuning.
# The model uses a binary logistic objective with logloss evaluation.
xgb_model = XGBClassifier(objective='binary:logistic',
                          use_label_encoder=False,
                          eval_metric='logloss',
                          random_state=42)

# 5. Define the hyperparameter search space for BayesSearchCV.
# The scale_pos_weight is fixed to the computed value, while other parameters are tuned over specified ranges [2]
param_space = {
    'max_depth': (3, 10),
    'learning_rate': (0.01, 0.3, 'uniform'),
    'n_estimators': (100, 1000),
    'subsample': (0.5, 1.0, 'uniform'),
    'colsample_bytree': (0.5, 1.0, 'uniform'),
    'scale_pos_weight': [scale_pos_weight]
}

# 6. Define fit parameters that include early stopping.
# These parameters tell XGBoost to stop training if logloss on the evaluation set does not improve for 50 rounds [7]
fit_params = {
    'eval_set': [(X_val, y_val)],
    'eval_metric': 'logloss',
    'early_stopping_rounds': 50,
    'verbose': False
}

# 7. Set up BayesSearchCV to optimize the F1 score (balancing precision and recall) over 3-fold CV.
bayes_cv = BayesSearchCV(
    estimator=xgb_model,
    search_spaces=param_space,
    scoring='f1',
    cv=3,
    n_iter=32,
    random_state=42,
    n_jobs=-1
)

# 8. Run BayesSearchCV with the early stopping parameters passed via fit_params.
bayes_cv.fit(X_train, y_train, **fit_params)
print("Best parameters from BayesSearchCV:")
print(bayes_cv.best_params_)

# 9. Determine the optimal probability threshold on the validation set.
# Instead of the default 0.5 threshold, we choose the threshold that maximizes the F1 score.
best_model = bayes_cv.best_estimator_
y_val_probs = best_model.predict_proba(X_val)[:, 1]
precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_probs)
# Compute F1 scores for candidate thresholds (using a small constant to avoid division-by-zero)
f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-8)
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx]
print("Optimal probability threshold for best F1 score:", optimal_threshold)

# 10. Evaluate the tuned model on the validation set with the chosen threshold.
y_pred_opt = (y_val_probs >= optimal_threshold).astype(int)
print("\nValidation Classification Report:")
print(classification_report(y_val, y_pred_opt))
print("Validation Confusion Matrix:")
print(confusion_matrix(y_val, y_pred_opt))

# 11. Re-fit the final model with the best parameters and early stopping.
final_model = XGBClassifier(**bayes_cv.best_params_,
                            objective='binary:logistic',
                            use_label_encoder=False,
                            eval_metric='logloss',
                            random_state=42)
final_model.fit(X_train, y_train, **fit_params)

# 12. Define a helper function to predict using the optimal threshold.
def predict_with_threshold(model, X, threshold=optimal_threshold):
    y_probs = model.predict_proba(X)[:, 1]
    return (y_probs >= threshold).astype(int)

final_predictions = predict_with_threshold(final_model, X_val)
print("\nFinal Model Classification Report with Optimal Threshold:")
print(classification_report(y_val, final_predictions))
