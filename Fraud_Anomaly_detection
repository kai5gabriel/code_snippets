Sure! Below is an **anomaly detection pipeline** for **fraud detection** using **Isolation Forest, Autoencoders, and Local Outlier Factor (LOF)**. This approach will help **detect new fraud behaviors** outside the modelâ€™s training data.  

---

## **ðŸ“Œ Steps in the Code**
1. **Load & Preprocess Data**  
2. **Train an Isolation Forest** (Unsupervised Anomaly Detection)  
3. **Train a Deep Autoencoder** (For High-Dimensional Data)  
4. **Train LOF (Local Outlier Factor)**  
5. **Compare Results Across Methods**  

---

### **ðŸ”¹ Step 1: Install Required Libraries**
```python
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
```

---

### **ðŸ”¹ Step 2: Load & Preprocess Data**
```python
# Load example transaction dataset
df = pd.read_csv("transactions.csv")  # Assume this has numerical transaction features

# Select relevant features (drop non-numeric columns)
num_cols = df.select_dtypes(include=[np.number]).columns
df = df[num_cols]

# Standardize numerical features
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)
```

---

### **ðŸ”¹ Step 3: Isolation Forest (Anomaly Detection)**
```python
# Train Isolation Forest
iso_forest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)
iso_forest.fit(df_scaled)

# Predict anomalies (-1 = anomaly, 1 = normal)
df["iso_forest_anomaly"] = iso_forest.predict(df_scaled)
df["iso_forest_anomaly"] = df["iso_forest_anomaly"].apply(lambda x: 1 if x == -1 else 0)
```

---

### **ðŸ”¹ Step 4: Autoencoder for Anomaly Detection**
```python
# Define Autoencoder model
input_dim = df_scaled.shape[1]
encoding_dim = 4  # Bottleneck layer size

autoencoder = keras.Sequential([
    layers.InputLayer(input_shape=(input_dim,)),
    layers.Dense(16, activation="relu"),
    layers.Dense(encoding_dim, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(input_dim, activation="linear")
])

# Compile model
autoencoder.compile(optimizer="adam", loss="mse")

# Train autoencoder
autoencoder.fit(df_scaled, df_scaled, epochs=50, batch_size=32, validation_split=0.1, verbose=0)

# Compute reconstruction error
df["reconstruction_error"] = np.mean(np.abs(df_scaled - autoencoder.predict(df_scaled)), axis=1)

# Flag anomalies (Top 1% highest errors)
threshold = np.percentile(df["reconstruction_error"], 99)
df["autoencoder_anomaly"] = df["reconstruction_error"].apply(lambda x: 1 if x > threshold else 0)
```

---

### **ðŸ”¹ Step 5: Local Outlier Factor (LOF)**
```python
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)
df["lof_anomaly"] = lof.fit_predict(df_scaled)
df["lof_anomaly"] = df["lof_anomaly"].apply(lambda x: 1 if x == -1 else 0)
```

---

### **ðŸ”¹ Step 6: Compare Results**
```python
# Compare anomaly detection methods
df["total_anomaly_score"] = df["iso_forest_anomaly"] + df["autoencoder_anomaly"] + df["lof_anomaly"]

# Flag transactions as fraudulent if detected by at least 2 models
df["final_anomaly"] = df["total_anomaly_score"].apply(lambda x: 1 if x >= 2 else 0)

# Show flagged anomalies
print(df[df["final_anomaly"] == 1])
```

---

## **ðŸ“Œ Key Takeaways**
âœ… **Isolation Forest** â†’ Detects outliers by isolating anomalies in fewer splits.  
âœ… **Autoencoder** â†’ Detects anomalies based on high reconstruction errors.  
âœ… **Local Outlier Factor (LOF)** â†’ Identifies points that deviate from local density.  
âœ… **Hybrid Model (Final Anomaly Score)** â†’ Uses multiple techniques to increase accuracy.  

Would you like help adapting this to your **banking fraud dataset**? ðŸš€
