Here's the revised code using **stratified K-fold cross-validation** for both model training and threshold tuning, followed by final evaluation on a held-out test set:

```python
import numpy as np
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve

# 1. Prepare data
X = ...  # Feature matrix
y = ...  # Target (1=fraud, 0=legitimate)

# Split into base train/test (keep test set untouched until final evaluation)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 2. Cross-validation setup
N_SPLITS = 5
skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)
oof_preds = np.zeros(len(X_train))  # Stores out-of-fold predictions
best_iterations = []
thresholds = []

# 3. Cross-validation loop
for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):
    X_fold_train, y_fold_train = X_train.iloc[train_idx], y_train.iloc[train_idx]
    X_fold_val, y_fold_val = X_train.iloc[val_idx], y_train.iloc[val_idx]
    
    # Initialize and train model with class balancing
    model = CatBoostClassifier(
        auto_class_weights='Balanced',
        eval_metric='AUC',
        early_stopping_rounds=50,
        iterations=1000,
        verbose=0,
        random_state=42
    )
    
    model.fit(
        X_fold_train, y_fold_train,
        eval_set=(X_fold_val, y_fold_val),
        use_best_model=True
    )
    
    # Store best iteration and predictions
    best_iterations.append(model.best_iteration_)
    oof_preds[val_idx] = model.predict_proba(X_fold_val)[:, 1]
    
    # Find optimal threshold for this fold
    precision, recall, thresh = precision_recall_curve(y_fold_val, oof_preds[val_idx])
    f1 = (2 * precision * recall) / (precision + recall + 1e-9)
    thresholds.append(thresh[np.argmax(f1)])

# 4. Determine final parameters
avg_best_iteration = int(np.mean(best_iterations))
final_threshold = np.mean(thresholds)  # Or use oof_preds for global optimization

# Optional: Global threshold optimization using all OOF predictions
precision, recall, thresh = precision_recall_curve(y_train, oof_preds)
f1 = (2 * precision * recall) / (precision + recall + 1e-9)
global_threshold = thresh[np.argmax(f1)]  # Often better than fold-average

# 5. Train final model on full training data
final_model = CatBoostClassifier(
    auto_class_weights='Balanced',
    iterations=avg_best_iteration,  # Use average best iteration from CV
    random_seed=42,
    verbose=0
).fit(X_train, y_train)

# 6. Evaluate on test set
test_proba = final_model.predict_proba(X_test)[:, 1]

# AUC score
test_auc = roc_auc_score(y_test, test_proba)
print(f"Test AUC: {test_auc:.3f}")

# F1 with optimized threshold
test_pred_global = (test_proba >= global_threshold).astype(int)
test_f1 = f1_score(y_test, test_pred_global)
print(f"Test F1 (Global Threshold {global_threshold:.3f}): {test_f1:.3f}")
```

### Key Improvements:
1. **Stratified K-fold Cross-Validation**  
   - Maintains class distribution in splits
   - Generates out-of-fold (OOF) predictions for robust threshold tuning

2. **Two Threshold Options**  
   - `final_threshold`: Average of per-fold thresholds  
   - `global_threshold`: Optimized using all OOF predictions (recommended)

3. **Efficient Final Training**  
   - Uses average best iteration count from CV to prevent overfitting  
   - Trains on 100% of training data with optimal parameters

4. **Metrics Tracking**  
   | Metric           | Description                              | Implementation          |
   |------------------|------------------------------------------|-------------------------|
   | OOF AUC          | Cross-validated AUC score                | `roc_auc_score(y_train, oof_preds)` |
   | Test AUC         | Final evaluation on unseen data         | Shown in code           |
   | Global F1        | Best F1 using OOF-optimized threshold    | Shown in code           |

This approach provides better generalization than a single validation split while maintaining a clean separation between training (CV) and final test data.
